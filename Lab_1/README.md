# **Техническое задание**  
## Разработка нейросети на NumPy (без PyTorch)  

### **1. Цель работы**  
Реализовать полносвязную нейросеть с использованием библиотеки NumPy, полностью повторив архитектуру и процесс обучения сети из предоставленного примера-туториала с сайта PyTorch.  

---

### **2. Задачи**  
1. **Использовать готовый датасет и DataLoader** из примера на PyTorch (без изменений).  
2. **Реализовать нейросеть средствами NumPy**:  
   - Прямой проход (forward pass).  
   - Обратный проход (backward pass).  
3. **Реализовать функцию потерь (Loss function)**.  
4. **Реализовать оптимизатор SGD** с нуля.  
5. **Обучить нейросеть** и сравнить результаты с PyTorch-версией.  
6. **Построить графики Loss** для обеих реализаций с помощью Matplotlib.  

---

### **3. Требования к реализации**  
- **Запрещено** использовать `torch.nn`, `torch.optim` и другие высокоуровневые модули PyTorch.  
- Разрешены только:  
  - `numpy` — для тензорных операций.  
  - `matplotlib` — для визуализации.  
  - Датасет и DataLoader — **только из примера** (PyTorch).  
- Архитектура сети и гиперпараметры должны полностью совпадать с эталонной реализацией.  

---

### **4. Результаты работы**  
1. Код нейросети на NumPy.  
2. Графики сходимости Loss для NumPy и PyTorch на одном полотне.  
3. Вывод о качестве обучения и скорости работы.  

---

### **5. Полезные материалы**  
1. [NumPy Quickstart](https://numpy.org/doc/stable/user/quickstart.html) — основы работы с массивами.  
2. [Matplotlib Pyplot Tutorial](https://matplotlib.org/stable/tutorials/pyplot.html) — построение графиков.  
3. [Объяснение нейросетей (MLU)](https://mlu-explain.github.io/neural-networks/) — теория обратного распространения.  
4. [PyTorch Basics](https://pytorch.org/tutorials/beginner/basics/intro.html) — только для эталонной реализации.  

---

### **6. Критерии оценки**  
- Корректность прямого и обратного проходов.  
- Идентичность Loss на старте и финальная точность.  
- Читаемость кода и наличие комментариев.  
- Качество визуализации.  
